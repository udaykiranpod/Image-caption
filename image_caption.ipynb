{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxZkTppSGk0q",
        "outputId": "84c8e728-a1e0-437f-8c0f-aa858a65a913"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge\n",
        "!pip\n",
        "!pip install Keras-Preprocessing\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os\n",
        "from pickle import dump, load\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import cv2\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import add\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense, LSTM, Embedding, Dropout\n",
        "from tensorflow.keras.applications.resnet import ResNet101\n",
        "import csv\n",
        "from rouge import Rouge\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qjowSIDnuOiH"
      },
      "source": [
        "### For Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRhVhOLvHE6H",
        "outputId": "b1bba2a1-e6c7-4128-a677-62482047ee4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JA5bvbsyHaww"
      },
      "outputs": [],
      "source": [
        "home = './MiniProject/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "skFiknEKGk0-"
      },
      "outputs": [],
      "source": [
        "# Loading a text file into memory\n",
        "def load_doc(filename):\n",
        "    file = open(filename, 'r')\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text\n",
        "\n",
        "# Loading a binary file into memory\n",
        "def load_doc_bin(filename):\n",
        "    file = open(filename, 'rb')\n",
        "    text = load(file)\n",
        "    file.close()\n",
        "    return text\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TAKixYHYuOiO"
      },
      "source": [
        "### Mapping image with descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ro9VrB5LGk1C"
      },
      "outputs": [],
      "source": [
        "# Mapping image with descriptions\n",
        "def all_img_captions(filename):\n",
        "    file = load_doc(filename)\n",
        "    captions = file.split('\\n')\n",
        "\n",
        "    descriptions ={}\n",
        "    for caption in captions[1:]:\n",
        "        #print(caption)\n",
        "        if caption == \"\" :\n",
        "          break\n",
        "        #cap=caption.split(\":\")\n",
        "        cap=caption.split(\",\")\n",
        "        \n",
        "        img = cap[0].strip()\n",
        "        \n",
        "        \n",
        "        caption_ = cap[1].strip()\n",
        "        \n",
        "        if img not in descriptions:\n",
        "            descriptions[img] = [caption_]\n",
        "        else:\n",
        "            descriptions[img].append(caption_)\n",
        "    # print(descriptions)\n",
        "    return descriptions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "u7FdScm2uOiQ"
      },
      "source": [
        "### Cleaning text in captions dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zVTorB5bGk1G"
      },
      "outputs": [],
      "source": [
        "#Changing to lower cases, removing punctuations and stop words and also numbers\n",
        "#this can be optimized\n",
        "def cleaning_text(captions):\n",
        "    table = str.maketrans('','', string.punctuation)\n",
        "    for img,caps in captions.items():\n",
        "        for i,img_caption in enumerate(caps):\n",
        "\n",
        "            img_caption.replace(\"-\",\" \")\n",
        "            desc = img_caption.split()\n",
        "\n",
        "            #convert to lower case\n",
        "            desc = [word.lower() for word in desc]\n",
        "            #remove punctuation\n",
        "            desc = [word.translate(table) for word in desc]\n",
        "            #remove 's and a    #intitution same removing stopwords in nlp\n",
        "            desc = [word for word in desc if(len(word)>1)]\n",
        "            #remove tokens with numbers\n",
        "            desc = [word for word in desc if(word.isalpha())]\n",
        "\n",
        "            img_caption = ' '.join(desc)\n",
        "            captions[img][i]= img_caption\n",
        "            \n",
        "    # print(list(captions.values())[0])\n",
        "    return captions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eSAIUnzHuOiS"
      },
      "source": [
        "### Creating Vocabulary from descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6YQmr2oDGk1J"
      },
      "outputs": [],
      "source": [
        "def text_vocabulary(descriptions):\n",
        "    vocab = set()\n",
        "    \n",
        "    for key in descriptions.keys():\n",
        "        [vocab.update(d.split()) for d in descriptions[key]]\n",
        "    \n",
        "    # print(vocab)\n",
        "    return vocab      #returing only unique words in captions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yMV9gInSuOiT"
      },
      "source": [
        "### Saving cleaned description to a file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-Cfj1xs2Gk1N"
      },
      "outputs": [],
      "source": [
        "#All descriptions in one file \n",
        "def save_descriptions(descriptions, filename):\n",
        "    lines = list()\n",
        "    for key, desc_list in descriptions.items():\n",
        "        for desc in desc_list:\n",
        "            lines.append(key + ' ' + desc )\n",
        "    data = \"\\n\".join(lines)\n",
        "    file = open(filename,\"w\")\n",
        "    file.write(data)\n",
        "    file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NxYlxcICGk1T",
        "outputId": "74bc86db-3a96-4592-c151-ec610d57751c",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of descriptions = 8091\n",
            "Length of vocabulary =  8571\n"
          ]
        }
      ],
      "source": [
        "filename = '/content/drive/MyDrive/MiniProject/captions.txt'\n",
        "\n",
        "descriptions = all_img_captions(filename)\n",
        "# print(description)/\n",
        "print(\"Length of descriptions =\" ,len(descriptions))\n",
        "\n",
        "clean_descriptions = cleaning_text(descriptions)\n",
        "\n",
        "vocabulary = text_vocabulary(clean_descriptions)\n",
        "print(\"Length of vocabulary = \", len(vocabulary))\n",
        "\n",
        "save_descriptions(clean_descriptions, '/content/drive/MyDrive/MiniProject/descriptions.txt')\n",
        "\n",
        "#using all the functions above such as cleaning and saving it in descriptions.txt\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3zAx9M4kuOiV"
      },
      "source": [
        "## RESNET MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGbMcuxhGk1Y"
      },
      "outputs": [],
      "source": [
        "resnet = ResNet101(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    pooling='avg'\n",
        ")\n",
        "resnet.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "puo0rfuNuOiW"
      },
      "source": [
        "### Creating features of image using RESNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2B34cVIGk1b"
      },
      "outputs": [],
      "source": [
        "def extract_features(directory):\n",
        "        features = {}\n",
        "        files = os.listdir(directory)\n",
        "        for image in files:\n",
        "            \n",
        "            filename = os.path.join(directory, image)\n",
        "            image = Image.open(filename)\n",
        "            \n",
        "            image = Image.open(filename)\n",
        "            image = image.resize((224,224))\n",
        "            image = np.expand_dims(image, axis=0)   #adding extra dimension and all of that put into resnet\n",
        "            feature = resnet.predict(image)  \n",
        "            features[filename] = feature\n",
        "        return features"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IwxlQH9KuOiW"
      },
      "source": [
        "### Dumping feature vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJC6l7EcGk1e"
      },
      "outputs": [],
      "source": [
        "features = extract_features('/content/drive/MyDrive/MiniProject/archive/Images')\n",
        "dump(features, open( os.path.join(os.getcwd(),'drive','MyDrive','MiniProject','image_features.p'),\"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTPX6lfGGk1g",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "features = load(open(\"features_10k.p\",\"rb\"))\n",
        "len(features)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sREAdwMAuOiX"
      },
      "source": [
        "### Loading everything into memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kb9R-pDIGk1j"
      },
      "outputs": [],
      "source": [
        "def load_clean_descriptions(filename):    \n",
        "    #loading clean_descriptions \n",
        "    file = load_doc(filename) \n",
        "    descriptions = {} \n",
        "    for line in file.split(\"\\n\"):         \n",
        "        words = line.split() \n",
        "        if len(words)<1 : \n",
        "            continue      \n",
        "        image, image_caption = words[0], words[1:]          \n",
        "        if image not in train_features.keys(): \n",
        "            continue  \n",
        "        if image not in descriptions: \n",
        "            descriptions[image] = [] \n",
        "        desc = '<startseq> ' + \" \".join(image_caption) + ' <endseq>' \n",
        "        descriptions[image].append(desc) \n",
        "    return descriptions \n",
        " \n",
        "def load_features(): \n",
        "    #loading all features \n",
        "    all_features = load_doc_bin('/content/drive/MyDrive/MiniProject/train_8K_6500.p')\n",
        "    return all_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrU2BMSyGk1l"
      },
      "outputs": [],
      "source": [
        "train_features = load_features() \n",
        "features = train_features \n",
        "train_descriptions = load_clean_descriptions('/content/drive/MyDrive/MiniProject/descriptions.txt') \n",
        "\n",
        "print(len(features)) "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Rrg_Wx7fuOiY"
      },
      "source": [
        "### Tokenizer to convert characters to integers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6QaqNT6Gk1m"
      },
      "outputs": [],
      "source": [
        "#converting dictionary to list of descriptions\n",
        "def dict_to_list(descriptions):\n",
        "    all_desc = []\n",
        "    for key in descriptions.keys():     #getting all the descrptions\n",
        "        [all_desc.append(d) for d in descriptions[key]]\n",
        "    return all_desc\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "def create_tokenizer(descriptions):\n",
        "    desc_list = dict_to_list(descriptions)\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(desc_list)\n",
        "    print(tokenizer)\n",
        "    return tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1DVghxSGk1n"
      },
      "outputs": [],
      "source": [
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "print(tokenizer.word_index)\n",
        "\n",
        "with open('/content/drive/MyDrive/MiniProject/tokenizer.p', 'wb') as token_file:\n",
        "    dump(tokenizer, token_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jrr1M3RJGk1o"
      },
      "outputs": [],
      "source": [
        "tokenizer = load_doc_bin('/content/drive/MyDrive/MiniProject/tokenizer.p')\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "vocab_size "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9yS7pQMyuOia"
      },
      "source": [
        "### Calculating Max length of descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHCagkN3Gk1p"
      },
      "outputs": [],
      "source": [
        "def max_length_func(descriptions):\n",
        "    desc_list = dict_to_list(descriptions)\n",
        "    max_ = 0\n",
        "    for d in desc_list:\n",
        "        if len(d.split()) > max_:\n",
        "            max_ = len(d.split())\n",
        "            # print(max_, d)\n",
        "    return max_\n",
        "\n",
        "max_length = max_length_func(descriptions)\n",
        "max_length"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YN_10hpaGk1r"
      },
      "source": [
        "#### Generator for training in-memory and preparing inputs for model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLBPI1Myvl50"
      },
      "outputs": [],
      "source": [
        "def data_generator(descriptions, features, tokenizer, max_length):\n",
        "    while 1:\n",
        "        for key, description_list in descriptions.items():\n",
        "            if key not in features.keys():\n",
        "              continue\n",
        "\n",
        "            feature = features[key][0]\n",
        "            input_image, input_sequence, output_word = create_sequences(tokenizer, max_length, description_list, feature)\n",
        "            yield [[input_image, input_sequence], output_word]\n",
        "\n",
        "def create_sequences(tokenizer, max_length, desc_list, feature):\n",
        "    X1, X2, y = list(), list(), list()\n",
        "\n",
        "    for desc in desc_list:\n",
        "        # encoding the sequence\n",
        "        seq = tokenizer.texts_to_sequences([desc])[0]\n",
        "        # split one sequence into multiple X,y pairs\n",
        "        for i in range(1, len(seq)):\n",
        "\n",
        "            in_seq, out_seq = seq[:i], seq[i]\n",
        "            in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "\n",
        "            X1.append(feature)\n",
        "            X2.append(in_seq)\n",
        "            y.append(out_seq)\n",
        "    return np.array(X1), np.array(X2), np.array(y)\n",
        "\n",
        "\n",
        "[a,b],c = next(data_generator(train_descriptions, features, tokenizer, max_length))\n",
        "a.shape, b.shape, c.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Se6MHOreuOic"
      },
      "source": [
        "## Resnet and LSTM MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uKeDKA2vyA5"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "def define_model(vocab_size, max_length):\n",
        "    \n",
        "    # features from the CNN model\n",
        "    # cnn_input = Input(shape=(2048,))\n",
        "    cnn_input = Input(shape=(2051,))\n",
        "    layer = Dropout(0.5)(cnn_input)\n",
        "    cnn_input = Dense(256, activation='relu')(layer)\n",
        "\n",
        "    # LSTM sequence model\n",
        "    lstm_input = Input(shape=(max_length,))\n",
        "    layer = Embedding(vocab_size, 256, mask_zero=True)(lstm_input)\n",
        "    layer = Dropout(0.5)(layer)\n",
        "    lstm_input = LSTM(256)(layer)\n",
        "\n",
        "    # Merging both models\n",
        "    merged_model = add([cnn_input, lstm_input])\n",
        "    merged_model = Dense(256, activation='relu')(merged_model)\n",
        "    outputs = Dense(vocab_size, activation='softmax')(merged_model)\n",
        "    \n",
        "    model = Model(inputs=[cnn_input, lstm_input], outputs=outputs)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
        "    \n",
        "    # summary of the model\n",
        "    # print(model.summary())\n",
        "    plot_model(model, to_file= '/content/drive/MyDrive/MiniProject/plotmodel.png', show_shapes=True)\n",
        "    print(model.summary)\n",
        "    return model\n",
        "\n",
        "m1=define_model(7784,29)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25P18GbtF4Ct"
      },
      "outputs": [],
      "source": [
        "print('Descriptions: train=', len(train_descriptions))\n",
        "print('Photos: train=', len(train_features))\n",
        "print('Vocabulary Size:', vocab_size)\n",
        "print('Description Length: ', max_length)\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "#Loading the saved model\n",
        "model = keras.models.load_model(\"/content/drive/MyDrive/MiniProject/model_20.h5\")\n",
        "\n",
        "epochs = 20\n",
        "steps = len(train_descriptions)\n",
        "# # os.mkdir(home+\"models test\")\n",
        "for i in range(12, epochs):\n",
        "    generator = data_generator(train_descriptions, train_features, tokenizer, max_length)\n",
        "    model.fit(generator, epochs=1, steps_per_epoch= steps, verbose=1)\n",
        "    model.save(home+\"models test1/model_\" + str(i) + \".h5\")\n",
        "    print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OFy_YecGNjT"
      },
      "outputs": [],
      "source": [
        "def word_for_id(integer, tokenizer):\n",
        " for word, index in tokenizer.word_index.items():\n",
        "     if index == integer:\n",
        "         return word\n",
        " return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8AnBWMPGX-C"
      },
      "outputs": [],
      "source": [
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "    in_text = 'startseq'\n",
        "    for i in range(max_length):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        pred = model.predict([photo,sequence], verbose=0)\n",
        "        pred = np.argmax(pred)\n",
        "        word = word_for_id(pred, tokenizer)\n",
        "        if word is None:\n",
        "            break\n",
        "        in_text += ' ' + word\n",
        "        if word == 'endseq':\n",
        "            break\n",
        "    return in_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f-MfGAbGZqZ"
      },
      "outputs": [],
      "source": [
        "def generate_feature(filename):\n",
        "    image = Image.open(filename)\n",
        "    image = image.resize((224,224))\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    return resnet.predict(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bGJAfTXGbrK"
      },
      "outputs": [],
      "source": [
        "f = open('/content/drive/MyDrive/MiniProject/predicted.csv','w')\n",
        "writer = csv.writer(f)\n",
        "writer.writerow(['Image','Caption Generated'])\n",
        "\n",
        "from glob import glob\n",
        "test_dir=glob('/content/drive/MyDrive/MiniProject/archive/TrainingImages/*.jpg')\n",
        "\n",
        "for image in test_dir:\n",
        "  description = generate_desc(model, tokenizer, generate_feature(image), max_length)\n",
        "  writer.writerow([image,description])\n",
        "f.close()\n",
        "# print(description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2nhxck9GeuY",
        "outputId": "71fab0e5-a469-4f88-ec40-84069cb5b347"
      },
      "outputs": [],
      "source": [
        "filename = \"/content/drive/MyDrive/MiniProject/archive/Images/109823394_83fcb735e1.jpg\"\n",
        "description = generate_desc(model, tokenizer, generate_feature(filename), 32)\n",
        "print(description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fumeshVxUlnE",
        "outputId": "39b9e4ac-c3f5-4f83-f8c3-c45a42d24820"
      },
      "outputs": [],
      "source": [
        "actual_captions = {}\n",
        "with open(\"/content/drive/MyDrive/MiniProject/descriptions.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        tokens = line.strip().split(\" \")\n",
        "        img_name, caption = tokens[0], \" \".join(tokens[1:])\n",
        "        if img_name not in actual_captions:\n",
        "            actual_captions[img_name] = [caption]\n",
        "        else:\n",
        "            actual_captions[img_name].append(caption)\n",
        "predicted_captions = {}\n",
        "with open(\"/content/drive/MyDrive/MiniProject/predicted.csv\", \"r\") as f:\n",
        "    next(f)\n",
        "    for line in f:\n",
        "        img_name, caption = line.strip().split(\",\")\n",
        "        img_name = img_name.split(\"/\")[-1]  # remove file path from image name\n",
        "        if img_name not in predicted_captions:\n",
        "            predicted_captions[img_name] = [caption]\n",
        "        else:\n",
        "            predicted_captions[img_name].append(caption)\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "total_score = 0.0\n",
        "num_captions = 0\n",
        "for img_name, pred_captions in predicted_captions.items():\n",
        "    actual_captions_for_img = actual_captions[img_name]\n",
        "    #print(\"This is the predicted caption\",pred_captions)\n",
        "\n",
        "    for pred_caption in pred_captions:\n",
        "        for actual_caption in actual_captions_for_img:\n",
        "            #print(\"this is actual caption\",actual_caption)\n",
        "            # tokenize both captions into lists of words\n",
        "            pred_tokens = pred_caption.strip().split(\" \")\n",
        "            actual_tokens = actual_caption.strip().split(\" \")\n",
        "            # compute BLEU score\n",
        "            score = sentence_bleu([actual_tokens], pred_tokens)\n",
        "            total_score += score\n",
        "        num_captions += 1\n",
        "\n",
        "\n",
        "print(\"Average BLEU score: {:.4f}\".format(total_score))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-e_z4ju8INx8",
        "outputId": "cb32cf66-2dad-4646-9735-389ec32c2d7a"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sdaC4bHjZf1w"
      },
      "outputs": [],
      "source": [
        "from nltk.translate.meteor_score import meteor_score\n",
        "from nltk.translate import meteor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS3vVarWrHle",
        "outputId": "c2d44fa5-be78-434c-bd40-659b89a6eb6f"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "actual_captions = {}\n",
        "with open(\"/content/drive/MyDrive/MiniProject/descriptions.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        tokens = line.strip().split(\" \")\n",
        "        img_name, caption = tokens[0], \" \".join(tokens[1:])\n",
        "        if img_name not in actual_captions:\n",
        "            actual_captions[img_name] = [caption]\n",
        "        else:\n",
        "            actual_captions[img_name].append(caption)\n",
        "\n",
        "predicted_captions = {}\n",
        "with open(\"/content/drive/MyDrive/MiniProject/predicted.csv\", \"r\") as f:\n",
        "    next(f)\n",
        "    for line in f:\n",
        "        img_name, caption = line.strip().split(\",\")\n",
        "        img_name = img_name.split(\"/\")[-1]  # remove file path from image name\n",
        "        if img_name not in predicted_captions:\n",
        "            predicted_captions[img_name] = [caption]\n",
        "        else:\n",
        "            predicted_captions[img_name].append(caption)\n",
        "\n",
        "total_score = 0.0\n",
        "num_captions = 0\n",
        "for img_name, pred_captions in predicted_captions.items():\n",
        "    actual_captions_for_img = actual_captions[img_name]\n",
        "\n",
        "    for pred_caption in pred_captions:\n",
        "        AT=[]\n",
        "        # print(\"predicted tokens are \",pred_caption)\n",
        "        for actual_caption in actual_captions_for_img:\n",
        "            # tokenize both captions into lists of words\n",
        "            pred_tokens = word_tokenize(pred_caption)\n",
        "            #pred_tokens = [token.lower() for token in pred_tokens]  # convert each token to lowercase\n",
        "            actual_tokens = word_tokenize(actual_caption)\n",
        "            AT.append(actual_tokens)\n",
        "            # print(actual_tokens)\n",
        "           \n",
        "            #actual_tokens = [token.lower() for token in actual_tokens]  # convert each token to lowercase\n",
        "            # compute METEOR score\n",
        "        score = nltk.translate.meteor_score.meteor_score(AT, pred_tokens)\n",
        "        total_score += score\n",
        "        num_captions += 1\n",
        "\n",
        "print(\"Average METEOR score: {:.4f}\")\n",
        "score = total_score\n",
        "score = score / 10\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cToeVCs32C6e",
        "outputId": "89d67891-d65e-4c95-e40c-2e70b31c4f30"
      },
      "outputs": [],
      "source": [
        "!pip install rouge_score\n",
        "\n",
        "from rouge_score import rouge_scorer\n",
        "import pandas as pd\n",
        "\n",
        "actual_captions = {}\n",
        "with open(\"/content/drive/MyDrive/MiniProject/descriptions.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        tokens = line.strip().split(\" \")\n",
        "        img_name, caption = tokens[0], \" \".join(tokens[1:])\n",
        "        if img_name not in actual_captions:\n",
        "            actual_captions[img_name] = [caption]\n",
        "        else:\n",
        "            actual_captions[img_name].append(caption)\n",
        "\n",
        "predicted_captions = {}\n",
        "with open(\"/content/drive/MyDrive/MiniProject/predicted.csv\", \"r\") as f:\n",
        "    next(f)\n",
        "    for line in f:\n",
        "        img_name, caption = line.strip().split(\",\")\n",
        "        img_name = img_name.split(\"/\")[-1]  # remove file path from image name\n",
        "        if img_name not in predicted_captions:\n",
        "            predicted_captions[img_name] = [caption]\n",
        "        else:\n",
        "            predicted_captions[img_name].append(caption)\n",
        "\n",
        "total_score = 0.0\n",
        "num_captions = 0\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "for img_name, pred_captions in predicted_captions.items():\n",
        "    actual_captions_for_img = actual_captions[img_name]\n",
        "\n",
        "    for pred_caption in pred_captions:\n",
        "        print(\"predicted caption is \", pred_caption)\n",
        "        \n",
        "        for actual_caption in actual_captions_for_img:\n",
        "            scores = scorer.score(pred_caption, actual_caption)\n",
        "            rouge_1 = scores['rouge1'].fmeasure\n",
        "            rouge_2 = scores['rouge2'].fmeasure\n",
        "            rouge_l = scores['rougeL'].fmeasure\n",
        "            \n",
        "            total_score += rouge_1 + rouge_2 + rouge_l\n",
        "            num_captions += 3  # We calculate three ROUGE scores for each pair of captions\n",
        "\n",
        "print(\"Average ROUGE score: {:.4f}\".format(total_score ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQXkSgsNjxHR"
      },
      "outputs": [],
      "source": [
        "print"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
